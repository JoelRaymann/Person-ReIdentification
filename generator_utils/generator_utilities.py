# For python 2 support
from __future__ import absolute_import, print_function, division, unicode_literals

# import necessary packages
import tensorflow as tf
from tensorflow.python import keras
from cv2 import cv2 as cv

# Import utility packages
import pandas as pd
import numpy as np

# Data Generator Class
class DataGenerator(keras.utils.Sequence):
    """
    Class which resizes the data and generates the data
    for the model to train. This class takes the metadata
    generated by the make_data.py file and makes batches of
    it and sends it to the model for training
    
    Prepares the following batch:
        X1 -- 224x224x3 image
        X2 -- 224x224x3 image
        y -- label
    """
    def __init__(self, dataset_metadata_path:str, batch_size:int, dim = (224, 224), n_channels = 3, n_classes = 2, shuffle = True):
        """
        A Class to act as a generator for batch-size wise data feed to the densenet-121.
        Generates {X1, X2, y} batch-wise data for the given options
    
        Arguments:
            dataset_metadata_path {str} -- The path to the meta-data .csv file for the dataset
            batch_size {int} -- The batch size to prepare
        
        Keyword Arguments:
            dim {tuple} -- The Dimension of the image input (default: {(224, 224)})
            n_channels {int} -- The channels in the input image. 3 for RGB image. 1 for grayscale
            n_classes {int} -- The number of output classes. Here it is 2
            shuffle {bool} -- The flag to shuffle or not (default: {True})
        """
        # Read meta data
        dataset_meta = pd.read_csv(dataset_metadata_path)

        # Get Path of all image dataset and labels
        self.sample1_path = list(dataset_meta.iloc[:, 0])
        self.sample2_path = list(dataset_meta.iloc[:, 1])
        self.labels = np.array(dataset_meta.iloc[:, 2], dtype = "float32")
        
        # Assign other variables
        self.batch_size = batch_size
        self.dim = dim
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.shuffle = shuffle
        self.indexes = np.arange(len(self.sample1_path))
        self.on_epoch_end()

    def __len__(self):
        """
        Function to return the total number of batches that
        would be generated per epoch
        """
        return int(np.floor(len(self.labels) / self.batch_size))
    
    def __data_generation(self, indexes_temp):
        """
        Function to generate a batch of the data with the given
        indexes range
        
        Arguments:
            indexes_temp {list} -- The list of indexes to fetch the
            batch of data
        """
        # Set up empty blocks to fill the data
        X1 = np.empty((self.batch_size, *self.dim, self.n_channels), dtype = "float32")
        X2 = np.empty((self.batch_size, *self.dim, self.n_channels), dtype = "float32")
        y = np.empty((self.batch_size, self.n_classes), dtype = "float32")

        # Fetch the data
        for i, index in enumerate(indexes_temp):
            # Read images
            img1 = cv.imread(self.sample1_path[index])
            img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)
            img1 = img1 / 255.
            img1 = cv.resize(img1, (self.dim[0], self.dim[1]), interpolation = cv.INTER_AREA)

            img2 = cv.imread(self.sample2_path[index])
            img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)
            img2 = img2 / 255.
            img2 = cv.resize(img2, (self.dim[0], self.dim[1]), interpolation = cv.INTER_AREA)

            # Fill it in
            X1[i, ] = img1
            X2[i, ] = img2
            y[i, ] = keras.utils.to_categorical(self.labels[index], num_classes = self.n_classes)

        return (X1, X2), y
    
    def __getitem__(self, index):
        """
        Function that generates one batch of the data with
        the index given
        
        Arguments:
            index {int} -- The index to generate the batch.i.e Batch index

        Returns:
            (X, y) -- returns X, y as a batch based on batch_size 
        """
        # Generate the list of indexes for the batch
        indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]
        # Return batch data
        return self.__data_generation(indexes)
    
    def on_epoch_end(self):
        """
        Function to handle the end of epoch state of a 
        model training. Here, we would do shuffling and
        preping the generator for the next epoch
        """
        if self.shuffle == True:
            np.random.shuffle(self.indexes)
